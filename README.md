# AI-Powered Chat Application

This repository contains a full-stack AI-powered chat application, showcasing LLM integration with a Python FastAPI backend and a Next.js (TypeScript) frontend. The application enables users to send messages through a chat interface and receive responses generated by a Large Language Model (LLM) via LangChain.

---

## Overview

This application enables users to interact with a chat interface that communicates with a Large Language Model (LLM) to generate responses. The key components include:

- **Backend:** A `FastAPI` server that integrates `LangChain` to interact with an LLM and exposes RESTful endpoints.
- **Frontend:** A `Next.js` (`TypeScript`) application that provides a minimal chat UI using Tailwind CSS and shadcn/ui components.
- **Monorepo:** The project is organized into `/backend` and `/frontend` directories within a single repository.
- **Containerization:** The application is Dockerized and supports deployment using `Docker Compose` for setup and deployment.

---

## System Architecture

- **Framework & LLM Integration:**  
  The backend is built with FastAPI and uses the [LangChain](https://github.com/hwchase17/langchain) library to interface with a Large Language Model (LLM). The key API endpoint is:
  - **POST `/api/chat`**: Accepts a JSON payload with a user message and returns the LLM’s response.
- **Coding Best Practices:**  
  The Python code adheres to PEP 8 standards, and Black is used to maintain a consistent code style.

- **Containerization:**  
  A Dockerfile is provided to containerize the backend service. Docker Compose is used to orchestrate both the backend and frontend services, ensuring a seamless local development experience.

- **Authentication & Deployment:**  
  While authentication isn’t implemented in this prototype, the backend README outlines a potential approach using JWTs or API keys. Deployment strategies, such as using Docker containers on a cloud platform, are also discussed.

### Frontend Architecture

- **Framework & UI:**  
  The frontend is built with Next.js and TypeScript, leveraging modern React practices (functional components, hooks) for a maintainable codebase.
- **User Interface:**  
  A minimal chat interface is implemented where users can input messages and view conversation history. Tailwind CSS and shadcn/ui components are used for styling and building UI elements such as text inputs and chat bubbles.

- **API Integration:**  
  The frontend communicates with the backend’s `/api/chat` endpoint using asynchronous calls (via the `fetch` API). Basic loading and error states are handled, and the design considers future support for streaming responses.

- **Code Organization:**  
  The project is organized into logical directories (pages, components, utils) to ensure scalability and ease of maintenance.

---

## Containerization & Deployment

- **Docker & Docker Compose:**  
  The entire application can be launched with a single command:

  ```bash
  docker compose up --build
  ```

---

## Future Enhancements

- Authentication (JWT, API keys, OAuth) to restrict access.
- Streaming API responses for real-time AI interactions.
- Cloud deployment (AWS/GCP) with CI/CD pipelines.

---

## Setup & Installation

### Backend Setup

Step 1. Create and activate virtual environment

```bash
python3 -m venv venv
source venv/bin/activate
```

Step 2. Install project dependencies

```bash
pip install black fastapi uvicorn langchain pydantic black python-dotenv huggingface_hub
pip install -U langchain-community langchain-huggingface
```

Step 3. Configure environment variables

1. Create `.env` file inside the `backend` directory.
2. Set value for `DEEPSEEK_API_TOKEN`.

Step 4. Start the backend server

```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

---

### Frontend Setup

Step 1. Create next.js project

```bash
npx create-next-app@latest --typescript frontend
cd frontend
```

Step 2. Install and configure dependencies

```bash
 npm install -D tailwindcss@3.3.3 postcss autoprefixer @shadcn/ui
```

Step 3. Configure TailwindCSS

Step 1. Create a file named `tailwind.config.js` inside the `frontend` project root.

```javascript
/** @type {import('tailwindcss').Config} */
module.exports = {
  content: ["./src/**/*.{js,jsx,ts,tsx}"],
  theme: {
    extend: {},
  },
  plugins: [],
};
```

Step 2. Create `postcss.config.js` file

```javascript
module.exports = {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
};
```

Step 3. Update global css file

Add directives at the top of `globals.css` file.

```css
@tailwind base;
@tailwind components;
@tailwind utilities;
```

Step 4. Initialize `shadcn`

```bash
npx shadcn@latest init
```

Step 5. Start frontend server

```bash
npm run dev
```
